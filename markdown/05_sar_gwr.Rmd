---
title: "Aplicando os modelos SAR e GWR"
date: "Junho de 2020"

output:
  html_document: 
    number_sections: no
    toc: yes
    code_folding: hide
---


```{r setup_exploration, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos =  "h")
knitr::opts_knit$set(root.dir = "../")

# libraries for data prep
library(dplyr)
library(stringr)

# libraries for spatial data manipulation
library(spatialreg)
library(maps)
library(maptools)    
library(rgdal)     
library(sp)  
library(spdep)
library(bamlss)
library(gstat)
library(splancs)
library(spatstat)
library(pgirmess)
library(classInt)
library(spgwr)

# libraries for plots and visualization
library(RColorBrewer)
library(tmap)
library(ggplot2)
library(ggExtra)

# libraries for markdown
library(knitr)
library(DT)

# libraries for modeling
library(MASS)
```

# Carregamento do shapefile, preparação e análises iniciais

O primeiro passo é o carregamento do shapefile, previamente preparado nas etapas anteriores, para iniciarmos uma análise iniciai quanto as variáveis.

```{r load_shapefile, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

dataProcessedDirectory <- "./data/processed/"
shapefile_to_read <- paste(dataProcessedDirectory, 
                           "gas_prices_hist", 
                           sep = "")
target <- readOGR(shapefile_to_read, encoding="UTF-8")

datatable(data = target@data[,c("CodIBGE", "Regiao", "Estado", "Cidade", "NmPostPesq", "PcMedRev")], 
          style = 'bootstrap', 
          options = list(pageLength = 10,autoWidth = TRUE))

```

## Variáveis presentes no dataset

Abaixo, vemos uma lista das variáveis presente no dataset do shapefile analisado.

```{r read_mnemonics, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

variables_list <- xlsx::read.xlsx("./data/processed/mnemonico.xlsx", sheetName = "gas_prices_hist", encoding="UTF-8")

datatable(data = variables_list, 
          style = 'bootstrap', 
          options = list(pageLength = 10,autoWidth = TRUE))

```

## Calculando os centróides e a matrix de vizinhança

Em seguida, obtém-se os centróides do shapefile para gerar a matrix de vizinhança dos polígonos espaciais e polígonos adjacentes através da biblioteca **spdep** usando a primeira ordem. A biblioteca **bamlss** será usada para gerar a matrix de vizinhança. O plot mostra o resultado desta configuração inicial.

```{r getting_nb, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

xy <- coordinates(target) 

ap <- poly2nb(target, queen = T, row.names = target$Index)
lw <- nb2listw(ap, style = "W", zero.policy = TRUE)
nm <- neighbormatrix(target, type = "boundary")

plotneighbors(target, type = "delaunay")

```

## Testando autocorrelação com I de Moran

O Índice de Moran Global (I) avalia a relação de interdependência espacial entre todos os polígonos da área de estudo e a expressa por meio de um valor único para toda a região. O Índice de Moran Local (Ii) identifica a relação existente entre um determinado polígono e a sua vizinhança, a partir de uma distância predefinida, por intermédio da covariância existente entre eles, permitindo o exame da homogeneidade/diversidade dos dados. Para este projeto, analisaremos o Índice de Moran Global.

```{r autocorrelation_i_moran, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

moran.test.NmPostPesq     <- moran.test(target$NmPostPesq, listw = lw, zero.policy = T) 
moran.test.PIB_2016 <- moran.test(target$PIB_2016, listw = lw, zero.policy = T)
moran.test.PIB_2017 <- moran.test(target$PIB_2017, listw = lw, zero.policy = T)
moran.test.PIBCap2016  <- moran.test(target$PIBCap2016, listw = lw, zero.policy = T)
moran.test.PIBCap2017   <- moran.test(target$PIBCap2017, listw = lw, zero.policy = T)
moran.test.PopEst  <- moran.test(target$PopEst, listw = lw, zero.policy = T)

moran.test.all <- rbind(t(data.frame("NmPostPesq" = moran.test.NmPostPesq$estimate)),
                        t(data.frame("PIB_2016" = moran.test.PIB_2016$estimate)),
                        t(data.frame("PIB_2017" = moran.test.PIB_2017$estimate)),
                        t(data.frame("PIBCap2016" = moran.test.PIBCap2016$estimate)),
                        t(data.frame("PIBCap2017" = moran.test.PIBCap2017$estimate)),
                        t(data.frame("PopEst" = moran.test.PopEst$estimate)))

moran.test.all <- as_tibble(moran.test.all, rownames = "Variables")
moran.test.all %>% arrange(desc(`Moran I statistic`))

datatable(data = moran.test.all, 
          style = 'bootstrap', 
          options = list(pageLength = 10,autoWidth = TRUE))

```

Focaremos nossa análise na variável **PIBCap2016**.

```{r i_moran_scatterplot, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

par(mar = c(4,4,1.5,0.5))
moran.plot(target$PIBCap2016, 
           listw = lw, 
           zero.policy = T,
           pch = 16, 
           col = "black",
           cex = .5, 
           quiet = F,
           labels = as.character(target$Cidade),
           xlab = "Percent for PIBCap2016",
           ylab = "Percent for PIBCap2016 (Spatial Lag)", 
           main = "Moran Scatterplot")

```

# Aplicando os modelos

Nas etapas a seguir, serão aplicados vários modelos a fim de entendermos se existe relacionamento espacial entre as variáveis do shapefile.

```{r model_initial_setup, echo = FALSE, out.width = '100%', fig.height = 6, warning = FALSE}

# initial setup
res.palette <- colorRampPalette(c("red","orange","white","lightgreen","green"), 
                                space = "rgb")
pal <- res.palette(5)
par(mar = c(2, 0, 4, 0))

```

## Implementando o modelo regressivo linear

Os modelos lineares de regressão são utilizados para modelar a relação entre variáveis quantitativas:

* **Variável Resposta (y):** variável quantitativa (também chamada de variável dependente).
* **Variáveis Preditoras (x):** variáveis quantitativas (também chamadas de variáveis independentes).

A função utilizada para construir modelos lineares de regressão é a função **lm**. 

```{r linear_regression_model, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

target.lm.model <- lm(PcMedRev ~ PIBCap2016, data = target)
summary(target.lm.model)

target.lm.model.residuals <- target.lm.model$residuals

target.lm.model.class_fx <- classIntervals(target.lm.model.residuals, 
                                           n = 5,
                                           style = "fixed",
                                           fixedBreaks = c(-50,-25,-5,5,25,50),
                                           rtimes = 1)

cols.lm <- findColours(target.lm.model.class_fx, pal)

plot(target, col = cols.lm, main = "OLS Model", border = "grey")
legend(x = "bottom", cex = 1, fill = attr(cols.lm, "palette"), bty = "n",
       legend = names(attr(cols.lm, "table")), title = "Residuals from OLS Model",
       ncol = 5)

moran.test(target.lm.model.residuals, listw = lw, zero.policy = T)

```

## Implementando o modelo espacial auto-regressivo (SAR) 

Um dos modelos mais comumente utilizados para modelagem de correlação espacial é  o  modelo  autorregressivo  espacial  (do inglês *spatial  autorregressive  model*),  ou  simplesmente modelo  SAR.  A  ideia  dos  modelos  SAR  é  utilizar  a  mesma  ideia  dos  modelos  AR (autorregressivos)  em  séries  temporais,  por  meio  da  incorporação  de  um  termo  de lagentre  os  regressores  da  equação.  

Na  sua  forma  mais simples,  o  modelo  SAR  tem expressão: 

$$\gamma = \rho W \gamma + \epsilon$$
Onde $\gamma$ é  um  vetor  coluna,  contendo *n* observações  na  amostra  para  a  variável  resposta $\gamma i$,  o  coeficiente  escalar $\rho$ corresponde  ao  parâmetro  autorregressivo,  esse  parâmetro possui  como  interpretação  o  efeito  médio  da  variável  dependente  relativo  à  vizinhança espacial  na  região  em  questão,  já  o  termo $\epsilon$ corresponde  a  um  vetor  coluna  contendo  os resíduos $\epsilon i$ da equação. Por enquanto, assume-se que os resíduos $\epsilon i$ são independentes e identicamente   distribuídos,   com   distribuição   normal,   com   média   zero   e   variância homogênea $\theta ^{2}$. Um  dos  componentes  presentes  em  uma  grande  quantidade  de  modelos espaciais  é  a  matriz $W$.  Esta  matriz  é  conhecida  como  matriz  de  vizinhança,  e  pode  ser definida  de  diversas  formas,  o  que  traz  críticas  aos  modelos  espaciais  utilizando $W$. Uma  das  formas  mais  comumente  empregadas  de  definição  da  matriz $W$ se  dá  por meio  da  identificação  de  vizinhos  de  primeira  ordem.  

```{r sar_model, echo = TRUE, out.width = '100%', fig.height = 6, warning = FALSE}

target.sar.model <- lagsarlm(PcMedRev ~ PIBCap2016, 
                             data = target, 
                             listw = lw,
                             zero.policy = T, 
                             tol.solve = 1e-12)
summary(target.sar.model)
target.sar.model$rest.se
target.sar.model$residuals

target.sar.model.residuals <- target.sar.model$residuals

target.sar.model.class_fx <- classIntervals(target.sar.model.residuals, 
                                            n = 5, 
                                            style = "fixed",
                                            fixedBreaks = c(-50,-25,-5,5,25,50),
                                            rtimes = 1)

cols.sar <- findColours(target.sar.model.class_fx, pal)

plot(target, col = cols.sar, main = "SAR Model", border = "grey")
legend(x = "bottom", cex = 1, fill = attr(cols.sar, "palette"), bty = "n",
       legend = names(attr(cols.sar, "table")), title = "Residuals from SAR Model",
       ncol = 5)

moran.test(target.sar.model.residuals, listw = lw, zero.policy = T)

```

